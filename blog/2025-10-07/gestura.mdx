---
slug: gestura
title: "ğŸ‘‹ Gestura: Gesture-Based Mouse & Voice Control"
authors: [Chirag Bhat, Zayn Baig]
date: 2025-10-07
tags: [FREE-WILi, mhacks, student project, hackathon]
---

> Gesture-based mouse built using FREE-WILi and Vosk text-to-speech used to increase accessibility in using the web for disabled people, such as amputees and people with lost-mobility in their hands.

import MyCarousel from '@site/src/components/Carousel';

{/* <MyCarousel /> */}

export const slides = [
  { type: 'video', src: '7x3D7nPJlRc' }, // YouTube video
  { type: 'image', src: '/img/blog/gestura.jpg', alt: 'gestura', caption: "Gestura: Gesture-Based Mouse & Voice Control" },
];

<MyCarousel slides={slides} />

<!-- truncate -->

<br/>

## ğŸ’¡ Inspiration

At theÂ **FREE-WILi workshop**Â held duringÂ **MHacks**Â this year, our team was inspired by a demo of aÂ **Theremin-like device**. It used hand gesturesâ€”detected via the FREE-WILiâ€™s accelerometerâ€”to control pitch and volume. This sparked an idea: what if we could harness similar gestures forÂ **accessibility**?

One of our teammates has a family member who suffers fromÂ **severe Rheumatoid Arthritis**, which makes traditional mouse and keyboard usage extremely difficult. We envisioned a system that would allow users to control a computer usingÂ **just hand gestures and voice commands**â€”no physical touch required.

Moreover, Gestura, which can be attached to the wrist or ankle, has a broader use forÂ **amputees**Â and other disabilities to allow people to regain theÂ **joy of digital interaction once again**.

---------------

## ğŸ§  What It Does

**Gestura**Â enables users toÂ **control their mouse using hand gestures**Â and perform mouse actions viaÂ **voice commands**.

*   **Hand gestures**Â detected by the FREE-WILi move the mouse across the screen.
*   **Voice commands**Â like:
    *   â€œleft clickâ€ 
    *   â€œright clickâ€
    *   â€œdouble clickâ€
    *   â€œscroll upâ€
    *   â€œscroll downâ€
    *   â€œholdâ€
    *   â€œreleaseâ€
    *   â€œpause inputâ€
    *   â€œresume inputâ€
        

This provides aÂ **touch-free**, accessible experience for users with limited mobility.

-------------------

## ğŸ› ï¸ How We Built It

We usedÂ **Python**Â and developed collaboratively withÂ **Git**Â andÂ **GitHub**.

### ğŸ“¦ Libraries & Tools Used

*   [`FREE-WILi`](https://pypi.org/project/freewili/): Interface with the FREE-WILi accelerometer.   
*   `pynput`: Control the mouse (movement and clicks).
*   `sounddevice`: Capture audio input via microphone.
*   `vosk`: Offline voice recognition usingÂ vosk-model-small.
    
### ğŸ® Mouse Movement via Accelerometer

*   CapturedÂ **X**Â andÂ **Y**Â acceleration using theÂ FREE-WILiÂ Python library. 
*   AppliedÂ **double integration**Â to convert acceleration toÂ **position**.
*   UsedÂ pynput.mouse.Controller.positionÂ to update the mouse location.

### ğŸ™ Voice Control

*   Captured real-time audio using theÂ **computerâ€™s microphone**.    
*   Processed input throughÂ **Vosk**Â for speech recognition.
*   Mapped voice inputs to actions like:
    *   click
    *   right click
    *   scroll up/down
    *   pause/resume input, etc.
        
-------------------

## ğŸš§ Challenges We Ran Into

*   **Sensor Drift & Offset**: The raw accelerometer data wasnâ€™t zero at rest, causing significant drift after integration.
    -  **Fix**: Introduced aÂ **deadband**Â (e.g.,Â ) to treat near-zero acceleration as zero.
      
*   **Erratic Movements**: Large spikes in acceleration led to uncontrollable motion.
    -   **Fix**: AddedÂ **min/max bounds**Â for both velocity and acceleration to stabilize gestures.
        
*   **Screen Bounds**: The mouse pointer would sometimes go off-screen.
    -   **Fix**: ImplementedÂ **position clamping**Â to ensure the mouse stays within the screen (1920x1080).
        
-------------------

## ğŸ† Accomplishments We're Proud Of

*   **Natural-feeling gesture control**Â after some practice.
*   **User feedback**: A friend testing it smiled when the device worked exactly as intended.
*   Implemented aÂ **broad command set**, from clicking to scrolling and pausing/resuming gesture input.
    
-------------------

## ğŸ“š What We Learned

*   TheÂ **FREE-WILi**Â device is powerful and versatile for prototyping assistive tech.
*   Sensor data in the real world can be noisyâ€”handling that is both science and art.
*   CombiningÂ **gesture + voice**Â control can dramatically improve accessibility.
    
--------------------------

## ğŸš€ Whatâ€™s Next for Gestura

*   ğŸ› ï¸ Build aÂ **gesture calibration tool**Â to personalize the experience.
*   ğŸ§  AddÂ **machine learning**Â to adapt gesture detection to each user over time.
*   ğŸŒ Integrate with web browsers for scroll, tab switch, and navigation.
*   ğŸ¤ Use theÂ **FREE-WILiâ€™s microphone**Â for full-device integration (once streaming support is added).

--------------------------

## ğŸ§© Built With  

```freewili```
```git```
```github```
```pynput```
```python```
```sounddevice```
```vosx```


### Try it out

<div class="github-img">

![GitHub](./github.png) <a href="https://github.com/imzaynb/MHacks2025" target="_blank"><span>GitHub Repo</span></a>
</div>

 *Source* - [https://devpost.com/software/gestura-9oaugq/](https://devpost.com/software/gestura-9oaugq/)
